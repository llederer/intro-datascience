"""
tokenization: breaks up text input in to several words/sentences

bag of words model: counts number of times a word shows up in tokens

sentiment lexicon: classifies total sentiment value of each text input

Process:
    1. Sign up to use Twitter's API
    2. Download Dependencies
    3. Write Code :-)
    
"""

